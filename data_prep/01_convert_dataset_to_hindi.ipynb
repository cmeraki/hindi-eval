{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e49584-c0f4-473e-b3bc-2d1d9cfd6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a027c-3bea-4187-ab9b-d0197bae786b",
   "metadata": {},
   "source": [
    "Hugginface open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30e42e-025b-4d2d-904a-3ecb9d5f79b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ultrachat = load_dataset('HuggingFaceH4/ultrachat_200k')\n",
    "translate_ds = load_dataset('ai4bharat/IN22-Gen', 'eng_Latn-hin_Deva')\n",
    "indic_qa = load_dataset('ai4bharat/IndicQA', 'indicqa.hi')\n",
    "# hindi_ds = load_dataset('ai4bharat/IN22-Gen', 'hin_Deva')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a201d-5eb7-40a2-bdce-e7741f9bb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = ultrachat['train_sft'].map(\n",
    "    utils.get_batch_tokens,\n",
    "    num_proc=20\n",
    ").map(utils.get_stringify_conversation, num_proc=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03020a50-7819-4c9e-9ab1-11a7d83ab064",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_ds['gen']['context'][0], translate_ds['gen']['sentence_hin_Deva'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6221eef9-9512-4b34-a486-e4606b61e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_english = \"\"\"\n",
    "user\n",
    "Which famous landmarks should I visit in London, beyond the usual ones?\n",
    "\n",
    "assistant\n",
    "You can visit Leadenhall Market - a beautiful indoor market with stunning Victorian architecture, also used as a filming location in the Harry Potter films.\n",
    "\n",
    "user\n",
    "Hmm, this is an interesting suggestion, but I've already seen this landmark in London. Is there something more offbeat that you can recommend? Something that locals might know about?\n",
    "\n",
    "assistant\n",
    "Absolutely! Here is an offbeat and lesser-known place in London that locals might recommend: God's Own Junkyard - a neon wonderland filled with vintage and new neon signs.\n",
    "There are many other hidden gems in London, and a quick Google search for ‘offbeat things in London’ will bring up many blogs and resources with more options.\n",
    "\"\"\"\n",
    "\n",
    "example_hindi = \"\"\"\n",
    "उपयोगकर्ता\n",
    "लंदन में मुझे कौन से प्रसिद्ध स्थल देखने चाहिए, जो आमतौर पर नहीं होते हैं?\n",
    "\n",
    "सहायक\n",
    "आप लेडनहॉल मार्केट देख सकते हैं - एक सुंदर इंडोर मार्केट जिसमें आकर्षक विक्टोरियन वास्तुकला है, जिसे हैरी पॉटर फिल्मों में फिल्मांकन स्थल के रूप में भी इस्तेमाल किया गया है।\n",
    "\n",
    "उपयोगकर्ता\n",
    "हम्म, यह एक दिलचस्प सुझाव है, लेकिन मैंने लंदन में इस स्थल को पहले ही देख लिया है। क्या आप कुछ और अनोखा सुझाव दे सकते हैं? कुछ ऐसा जो स्थानीय लोगों को पता हो?\n",
    "\n",
    "सहायक\n",
    "बिल्कुल! यहां लंदन में एक अनोखा और कम जाना-पहचाना स्थल है जिसकी स्थानीय लोग सिफारिश कर सकते हैं: गॉड्स ओन जंकयार्ड - एक नियॉन वंडरलैंड जो पुराने और नए नियॉन साइन्स से भरा हुआ है।\n",
    "लंदन में कई अन्य छुपे हुए रत्न हैं, और ‘लंदन में अनोखी चीजें’ के लिए गूगल सर्च करने पर आपको कई ब्लॉग्स और संसाधन मिल जाएंगे जिनमें और भी विकल्प होंगे।\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643b94c-4d86-4b85-bdce-60363820a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translate_query(example: Dict, example_english, example_hindi):\n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an expert tranlator who traslates given text in English to Devnagri Hindi\"\n",
    "    }\n",
    "\n",
    "    user_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Translate {example_english} to Devnagri Hindi\"\n",
    "    }\n",
    "\n",
    "    assistant_prompt = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"{example_hindi}\"\n",
    "    }\n",
    "\n",
    "    translate_prompt = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f'Translate {example[\"str_msg\"]} to Devnagri Hindi'\n",
    "    }\n",
    "\n",
    "    example[\"text\"] = [system_prompt, user_prompt, assistant_prompt, translate_prompt]\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2a08b-7767-4f2f-a845-08e9b7a0f154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_ds = raw_ds.map(\n",
    "    lambda x: get_translate_query(x, example_english, example_hindi),\n",
    "    num_proc=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052f903-8738-4b9b-a545-c3842659ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_ds['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f57ce-e6b9-4436-b4a7-dc33fd0dd254",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eng_ds = translate_ds['gen']['sentence_eng_Latn'][0:1000]\n",
    "raw_hind_ds = translate_ds['gen']['sentence_hin_Deva'][0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40952faa-4ccd-4e3f-bac4-3d09489c8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_toks = []\n",
    "\n",
    "for e in raw_eng_ds:\n",
    "    eng_toks.append(utils.get_tokens_from_messages([e]))\n",
    "\n",
    "hin_toks = []\n",
    "\n",
    "for e in raw_hind_ds:\n",
    "    hin_toks.append(utils.get_tokens_from_messages([e]))\n",
    "\n",
    "mult = np.divide(hin_toks, eng_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a78ce-f709-48cf-8d0b-11527daa46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(eng_toks, label='eng token')\n",
    "plt.hist(hin_toks, label='hin toens')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2938386-e0f6-42a6-9101-d1e25369eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mult), np.percentile(mult, 95), np.percentile(mult, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d94b1-95c6-47a6-935d-178b87085aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mult)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf510b-8194-4b94-bec9-41e6f58a523e",
   "metadata": {},
   "source": [
    "On an average, the hindi translation outputs 4-5x number of tokens. So the total number of tokens in a single message needs to be:\n",
    "- prompt len (p)\n",
    "- conversation len in english (x)\n",
    "- expected response len in hindi (5x)\n",
    "\n",
    "p + x + 5x < 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa752a2-0dc1-4108-b61d-924c01fcb910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_gpt_translate_prompts(ex_eng, ex_hi, src_msg: List, token_limit: int = 4069):\n",
    "    \"\"\"\n",
    "    Prepare a single prompt for input to GPT\n",
    "    \"\"\"\n",
    "\n",
    "    translate_prompt = \"\"\"This is a conversation between the User and the Assistant in English.\n",
    "    \n",
    "    {example_english}\n",
    "    \n",
    "    This is the translation of the above conversation in Devnagri Hindi\n",
    "    \n",
    "    {example_hindi}\n",
    "    \n",
    "    Similary translate the following conversation from English to Devnagri Hindi\n",
    "    \n",
    "    \"\"\".format(\n",
    "        example_english=ex_eng,\n",
    "        example_hindi=ex_hi\n",
    "    )\n",
    "\n",
    "    completion_prompt = translate_prompt\n",
    "    p = utils.get_tokens_from_messages([completion_prompt])\n",
    "    print(f'Prompt length: {p}')\n",
    "\n",
    "    for elem in src_msg:\n",
    "        flat_elem = utils.stringify(elem)\n",
    "        x = utils.get_tokens_from_messages([flat_elem])\n",
    "        c = utils.get_tokens_from_messages([completion_prompt])\n",
    "\n",
    "        print(f'Conversation length until now: {x+c}')\n",
    "\n",
    "        if 6*x + c > token_limit:\n",
    "            yield completion_prompt\n",
    "            completion_prompt = translate_prompt\n",
    "        \n",
    "        completion_prompt += flat_elem\n",
    "\n",
    "    yield completion_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de1e01-6606-4ab5-a22f-910d0fc41d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_to_gpt = prepare_gpt_translate_prompts(\n",
    "    ex_eng=example_english,\n",
    "    ex_hi=example_hindi,\n",
    "    src_msg=ultrachat['train_sft']['messages'][2],\n",
    "    token_limit=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb5199b-14ce-4a01-b40c-dba4cb3e5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_msgs = []\n",
    "\n",
    "for e in msg_to_gpt:\n",
    "    all_msgs.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7cfa3c-8d24-47f3-9819-e2066f9f28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_tokens_from_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9cb0a-bf91-41d4-8afd-3c0af8497518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
