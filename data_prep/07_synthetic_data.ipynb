{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu = load_dataset('lukaemon/mmlu', 'elementary_mathematics')\n",
    "ds = mmlu['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': dedent('''\n",
    "        You are an helpful assistant who produces synthetic data in devnagri Hindi.\n",
    "        Generate a new question for 8th grade {subject} exam.\n",
    "        Always reply with a new question, 4 choices for the answers and the correct answer.\n",
    "        You always output in JSON format.\n",
    "    ''').strip().format(subject='elementary mathematics')\n",
    "}\n",
    "\n",
    "example_prompt = dedent('''\n",
    "    Question: {question}\n",
    "\n",
    "    Choices:\n",
    "        A: {option_a}\n",
    "        B: {option_b}\n",
    "        C: {option_c}\n",
    "        D: {option_d}\n",
    "\n",
    "    Target: {target}\n",
    "''').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = {\n",
    "    'role': 'user',\n",
    "    'content': example_prompt.format(\n",
    "        question=ds[2]['input'],\n",
    "        option_a=ds[2]['A'],\n",
    "        option_b=ds[2]['B'],\n",
    "        option_c=ds[2]['C'],\n",
    "        option_d=ds[2]['D'],\n",
    "        target=ds[2]['target']\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_prompt['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"question\": <>,\n",
    "    \"A\": <>,\n",
    "\n",
    "    \"TARGET\": <>\n",
    "}\n",
    "\n",
    "- dataset save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompt['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = {\n",
    "    'role': 'user',\n",
    "    'content': dedent(\"\"\"\n",
    "    {'QUESTION': <>, 'A': <>, 'B': <>, 'C': <>, 'D': <>, 'TARGET': <>}\n",
    "    \"\"\").strip()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([system_prompt, user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    completions = client.chat.completions.create(\n",
    "        model='gpt-4-1106-preview',\n",
    "        response_format={'type': 'json_object'},\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            user_prompt\n",
    "        ],\n",
    "        temperature=1.5\n",
    "    )\n",
    "\n",
    "    if completions.choices[0].finish_reason == 'length':\n",
    "        raise IOError('Reached maximum output length')\n",
    "\n",
    "    try:\n",
    "        op = json.loads(completions.choices[0].message.content)\n",
    "    except:\n",
    "        raise ValueError('Value returned by the model is not valid JSON')\n",
    "\n",
    "    print(f'Tokens used\" {completions.usage}')\n",
    "\n",
    "except Exception as err:\n",
    "    print(f'Error raised in accesing the API: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ques = 1000\n",
    "\n",
    "time_to_response = 40\n",
    "input_tokens = 200\n",
    "output_tokens = 600\n",
    "\n",
    "tok_ps = (input_tokens + output_tokens)/time_to_response\n",
    "\n",
    "input_price = 0.01/1000\n",
    "output_price = 0.03/1000\n",
    "\n",
    "\n",
    "total_price = (input_price * input_tokens + output_price * output_tokens) * total_ques\n",
    "total_time = total_ques * time_to_response\n",
    "\n",
    "print(round(total_price, 2), round(total_time/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse into pydantic class (so that we can verify)\n",
    "# and add to responses list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hindi articles generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': dedent('''\n",
    "        You are an helpful assistant who produces synthetic data in colloquial Devnagri Hindi.\n",
    "        The data should be relevant to India.\n",
    "    ''').strip()\n",
    "}\n",
    "\n",
    "user_prompt = {\n",
    "    'role': 'user',\n",
    "    'content': 'Generate a fictional story set in a school classroom (200-600 words)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    completions = client.chat.completions.create(\n",
    "        model='gpt-4-1106-preview',\n",
    "        # response_format={'type': 'json_object'},\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            user_prompt,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if completions.choices[0].finish_reason == 'length':\n",
    "        raise IOError('Reached maximum output length')\n",
    "\n",
    "    try:\n",
    "        op = json.loads(completions.choices[0].message.content)\n",
    "    except:\n",
    "        raise ValueError('Value returned by the model is not valid JSON')\n",
    "\n",
    "    print(f'Tokens used\" {completions.usage}')\n",
    "\n",
    "except Exception as err:\n",
    "    print(f'Error raised in accesing the API: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completions.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~1800 tokens = 90 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from typing import Tuple\n",
    "from configs.synthetic_dataset import GenerationConfiguration, synthetic_dataset_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTGenerator():\n",
    "    def __init__(self, model_id) -> None:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "\n",
    "        self.client = openai.OpenAI()\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def __call__(self, system_prompt: str, user_prompt: str = None, temperature: float = 1.4) -> Tuple:\n",
    "        messages = [system_prompt]\n",
    "        if user_prompt:\n",
    "            messages.append(user_prompt)\n",
    "        print('here')\n",
    "        completions = self.client.chat.completions.create(\n",
    "            model=self.model_id,\n",
    "            response_format={'type': 'json_object'},\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        print('here')\n",
    "\n",
    "        if completions.choices[0].finish_reason == 'length':\n",
    "            raise IOError(\n",
    "                'Reached maximum output length, output format is not reliable')\n",
    "\n",
    "        op = json.loads(completions.choices[0].message.content)\n",
    "\n",
    "        print(f'Tokens used in generation using {self.model_id}: {completions.usage}')\n",
    "        print(f'Completion output from Open AI APIs: {completions}')\n",
    "\n",
    "        return op, completions.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GPTGenerator('gpt-3.5-turbo-1106')\n",
    "\n",
    "total_usage = {\n",
    "    'input': 0,\n",
    "    'output': 0,\n",
    "}\n",
    "generated_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, synth_ds in synthetic_dataset_models.items():\n",
    "    print(f'Generating synthetic dataset for {synth_ds.name}')\n",
    "\n",
    "    try:\n",
    "        sys_prompt = {\n",
    "            'role': 'system',\n",
    "            'content': synth_ds.system_prompt.format(\n",
    "                language='Devnagri Hindi',\n",
    "                subject='Physics',\n",
    "                grade='8th Grade',\n",
    "                topic='Basic Forces and Motion',\n",
    "                required_format=synth_ds.required_format\n",
    "            )\n",
    "        }\n",
    "        datapoint, usage = generator(\n",
    "            system_prompt=sys_prompt,\n",
    "            temperature=GenerationConfiguration.temperature\n",
    "        )\n",
    "        total_usage['input'] += usage.prompt_tokens\n",
    "        total_usage['output'] += usage.completion_tokens\n",
    "\n",
    "        print(f'Return datapoint: {datapoint}')\n",
    "\n",
    "        assert synth_ds.response_model.model_validate(datapoint), \"Response by the model is not in the valid dataform\"\n",
    "        generated_dataset.append(datapoint)\n",
    "\n",
    "    except openai.RateLimitError as err:\n",
    "        print(f'Reached rate limit: {err}')\n",
    "        break\n",
    "    except Exception as err:\n",
    "        print(f'Raised error: {err}')\n",
    "\n",
    "    print(f'Used cumulative tokens: {total_usage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_list(generated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
