{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu = load_dataset('lukaemon/mmlu', 'elementary_mathematics')\n",
    "ds = mmlu['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': dedent('''\n",
    "        You are an helpful assistant who produces synthetic data in the subject of {subject}.\n",
    "        Always reply with question and 4 choices for the answers.\n",
    "        Generate a new question in the similar fashion to what has been shared.\n",
    "        You always output in JSON format.\n",
    "    ''').strip().format(subject='elementary mathematics')\n",
    "}\n",
    "\n",
    "example_prompt = dedent('''\n",
    "    Question: {question}\n",
    "\n",
    "    Choices:\n",
    "        A: {option_a}\n",
    "        B: {option_b}\n",
    "        C: {option_c}\n",
    "        D: {option_d}\n",
    "''').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = {\n",
    "    'role': 'user',\n",
    "    'content': example_prompt.format(\n",
    "        question=ds[0]['input'],\n",
    "        option_a=ds[0]['A'],\n",
    "        option_b=ds[0]['B'],\n",
    "        option_c=ds[0]['C'],\n",
    "        option_d=ds[0]['D'],\n",
    "    )\n",
    "}\n",
    "\n",
    "assistant_prompt = {\n",
    "    'role': 'assistant',\n",
    "    'content': '''\n",
    "    {\n",
    "    \"Question\": \"Olivia used the rule 'Add 11' to create the number pattern shown below. 10, 21, 32, 43, 54. Which statement about the number pattern is true?\",\n",
    "    \"Choices\": {\n",
    "        \"A\": \"The 10th number in the pattern will be an even number.\",\n",
    "        \"B\": \"The number pattern will never have two even numbers next to each other.\",\n",
    "        \"C\": \"The next two numbers in the pattern will be an even number then an odd number.\",\n",
    "        \"D\": \"If the number pattern started with an odd number then the pattern would have only odd numbers in it.\"\n",
    "    }\n",
    "    }\n",
    "    '''\n",
    "}\n",
    "\n",
    "user_prompt1 = {\n",
    "    'role': 'user',\n",
    "    'content': example_prompt.format(\n",
    "        question=ds[1]['input'],\n",
    "        option_a=ds[1]['A'],\n",
    "        option_b=ds[1]['B'],\n",
    "        option_c=ds[1]['C'],\n",
    "        option_d=ds[1]['D'],\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    completions = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo-1106',\n",
    "        response_format={'type': 'json_object'},\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            # user_prompt,\n",
    "            # assistant_prompt,\n",
    "            user_prompt1\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if completions.choices[0].finish_reason == 'length':\n",
    "        raise IOError('Reached maximum output length')\n",
    "\n",
    "    try:\n",
    "        op = json.loads(completions.choices[0].message.content)\n",
    "    except:\n",
    "        raise ValueError('Value returned by the model is not valid JSON')\n",
    "\n",
    "    print(f'Tokens used\" {completions.usage}')\n",
    "\n",
    "except Exception as err:\n",
    "    print(f'Error raised in accesing the API: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(op, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse into pydantic class (so that we can verify)\n",
    "# and add to responses list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hindi articles generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': dedent('''\n",
    "        You are an helpful assistant who produces synthetic data in colloquial Devnagri Hindi.\n",
    "        The data should be relevant to India.\n",
    "    ''').strip()\n",
    "}\n",
    "\n",
    "user_prompt = {\n",
    "    'role': 'user',\n",
    "    'content': 'Generate a fictional story set in a school classroom (200-600 words)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    completions = client.chat.completions.create(\n",
    "        model='gpt-4-1106-preview',\n",
    "        # response_format={'type': 'json_object'},\n",
    "        messages=[\n",
    "            system_prompt,\n",
    "            user_prompt,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if completions.choices[0].finish_reason == 'length':\n",
    "        raise IOError('Reached maximum output length')\n",
    "\n",
    "    try:\n",
    "        op = json.loads(completions.choices[0].message.content)\n",
    "    except:\n",
    "        raise ValueError('Value returned by the model is not valid JSON')\n",
    "\n",
    "    print(f'Tokens used\" {completions.usage}')\n",
    "\n",
    "except Exception as err:\n",
    "    print(f'Error raised in accesing the API: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completions.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completions.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~1800 tokens = 90 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
