{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e8f13-d3f5-4848-aea7-b3222bb8b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_from_disk, Dataset\n",
    "import backoff\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b9506-e6eb-4065-b927-cfa0b5f1e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTGenerator():\n",
    "    def __init__(self, model_id) -> None:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "\n",
    "        self.client = openai.OpenAI()\n",
    "        self.model_id = model_id\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, openai.RateLimitError, max_time=300)\n",
    "    def __call__(self, messages: List[str], temperature: float = 1.4) -> Tuple[Dict, any]:\n",
    "\n",
    "        completions = self.client.chat.completions.create(\n",
    "            model=self.model_id,\n",
    "            response_format={'type': 'json_object'},\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            # max_tokens=2048\n",
    "        )\n",
    "\n",
    "        if completions.choices[0].finish_reason == 'length':\n",
    "            raise IOError(f'Reached maximum output length, output format is not reliable. {completions.choices[0].message.content}')\n",
    "\n",
    "        op = json.loads(completions.choices[0].message.content)\n",
    "\n",
    "        # print(f'Prompts: {messages}, output: {op}')\n",
    "        # print(f'Tokens used in generation using {self.model_id}: {completions.usage}')\n",
    "\n",
    "        return op, completions.usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5d39d-df23-4a64-952a-b69db03c42e7",
   "metadata": {},
   "source": [
    "## Retrieval dataset\n",
    "- Load the generated dataset\n",
    "- Standardize the schema of the dataset\n",
    "- Schema of the dataset\n",
    "    - QUESTION (str)\n",
    "    - TYPE (enum <'fill_in_the_blanks', 'true_false', 'mcq'>)\n",
    "    - CHOICES (list)\n",
    "    - TARGET (0-indexed option from the CHOICES list)\n",
    "    - PASSAGE_HASH (hash of the passage id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb6000-aebb-4d03-8a0b-694563689aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_articles_path = '../data/retrieval/cleaned_dataset/dataset.jsonl'\n",
    "generated_data_path = '../data/synthetic_data/20231229-1712/retrieval_questions/dataset.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8cb8b8-d907-4cd6-9ee6-0d83fcf6e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_jsonl(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        raw = fp.read()\n",
    "        data = []\n",
    "\n",
    "    for ln in raw.split('\\n'):\n",
    "        if not ln:\n",
    "            continue\n",
    "        data.append(json.loads(ln))\n",
    "\n",
    "    print(f'Loaded dataset with {len(data)} rows')\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa5ab9-36c8-4ccb-9ec6-cf64bb311202",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ds = load_from_jsonl(raw_articles_path)\n",
    "synthetic_ds = load_from_jsonl(generated_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5110a4-2551-47d6-a625-e32bbd8d9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ds.drop_duplicates(subset=['link'], inplace=True)\n",
    "synthetic_ds.drop(synthetic_ds.columns[-2:], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ee93e-63e9-4bec-bbf6-b5ad63464d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84220634-5ae1-4dad-9158-99167c00ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping multiple catetgories to a standard category\n",
    "type_mapper = {\n",
    "    'Fill in the Blank': 'fill_in_the_blanks',\n",
    "    'True/False': 'true_false',\n",
    "    'MCQ': 'mcq',\n",
    "    'FILL_BLANK': 'fill_in_the_blanks',\n",
    "    'TRUE_FALSE': 'true_false',\n",
    "    'Fill in the blank': 'fill_in_the_blanks',\n",
    "    'One word fill in the blanks': 'fill_in_the_blanks',\n",
    "    'Fill in the blanks': 'fill_in_the_blanks',\n",
    "    'FillInBlank': 'fill_in_the_blanks',\n",
    "    'TrueFalse': 'true_false',\n",
    "    'FILL IN THE BLANK': 'fill_in_the_blanks',\n",
    "    'One Word': 'fill_in_the_blanks',\n",
    "    'One word': 'fill_in_the_blanks',\n",
    "    'One_word_fill_in_the_blanks': 'fill_in_the_blanks',\n",
    "    'FILL_IN_THE_BLANKS': 'fill_in_the_blanks',\n",
    "    'One-word': 'fill_in_the_blanks',\n",
    "    'Fill in the Blanks': 'fill_in_the_blanks',\n",
    "    'One word Fill in the blank': 'fill_in_the_blanks',\n",
    "    'FILL_IN_THE_BLANK': 'fill_in_the_blanks',\n",
    "    'Unknown Type': 'mcq',\n",
    "    'Nonsensical Instructions,(waitlisting_unset.dispatch_profile_update)%  <Give_Statics_of_ShareMarket>': 'mcq',\n",
    "    'Unintelligible Question': 'mcq',\n",
    "    'False assumptions premise': 'true_false',\n",
    "    'Truth/Own assumptions': 'true_false',\n",
    "    'Fill-in-the-blank': 'fill_in_the_blanks',\n",
    "    'Text': 'mcq',\n",
    "    'TRUE/FALSE': 'true_false',\n",
    "    'Solution_Seeker_TrueFalse': 'true_false',\n",
    "    'One Word Fill In The Blanks': 'fill_in_the_blanks',\n",
    "    'FillInTheBlank': 'fill_in_the_blanks',\n",
    "    'FILL IN THE BLANKS': 'fill_in_the_blanks',\n",
    "    'One Word Fill in the blanks': 'fill_in_the_blanks',\n",
    "    'Fill-in-the-Blank': 'fill_in_the_blanks'\n",
    "}\n",
    "\n",
    "synthetic_ds['CLEANED_TYPE'] = synthetic_ds.TYPE.apply(lambda x: type_mapper[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8d98a-3e82-4f00-843b-fdf8e465113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ds = synthetic_ds.merge(\n",
    "    articles_ds,\n",
    "    left_on='PASSAGE_LINK',\n",
    "    right_on='link',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035102cc-896f-4ce3-8da8-9d8b044f018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If choices is NA, drop for MCQ and fill in the blanks\n",
    "# If the type is not TRUE_FALSE and choice array is lt 2 then drop\n",
    "print(f'Initial size: {merged_ds.shape}')\n",
    "print(merged_ds.query(\"CHOICES.isna()\").groupby('CLEANED_TYPE').size())\n",
    "\n",
    "# Length of the CHOICES array\n",
    "def arr_len(x):\n",
    "    if x is None or type(x) != list:\n",
    "        return -1\n",
    "    return len(x)\n",
    "\n",
    "merged_ds['CHOICES_LEN'] = merged_ds.CHOICES.apply(arr_len)\n",
    "\n",
    "merged_ds = merged_ds.query(\"(CHOICES.notna() and CHOICES_LEN >=2) or CLEANED_TYPE == 'true_false'\")\n",
    "print(f'Final size: {merged_ds.shape}')\n",
    "\n",
    "print(merged_ds.groupby(['CLEANED_TYPE', 'CHOICES_LEN']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2314d-04ef-4971-a40e-dcea08ac286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer = GPTGenerator(model_id='gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b3595-d1ca-420f-8b03-e7e00a288531",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': dedent('''\n",
    "    You are helpful assistant who is an expert in data cleaning\n",
    "    You will be provided with a JSON with the schema:\n",
    "    {'CHOICES': <>, 'TARGET': <>}\n",
    "    \n",
    "    You have to return a cleaned and standardized JSON with the schema.\n",
    "    {'CHOICES': <>, 'TARGET': <>, 'CLEAN_CHOICES': <>, 'CLEAN_TARGET': <>}\n",
    "    \n",
    "    Clean the JSON provided following the rules:\n",
    "    - Return [True, False] in the CLEAN_CHOICES key\n",
    "    - TARGET can either be the correct index in the 0th indexed list CHOICES or not given\n",
    "    - If TARGET is not given, it needs to be inferred from the given TARGET and CHOICES and populated into CLEAN_TARGET\n",
    "    - The CLEAN_TARGET might not always be 0 \n",
    "\n",
    "    Return with the cleaned JSON only\n",
    "    ''').strip()\n",
    "}\n",
    "\n",
    "ex1_prompt = {\n",
    "    'role': 'user',\n",
    "    'name': 'example_user1',\n",
    "    'content': \"{'CHOICES': [सत्य, असत्य], 'TARGET': 'असत्य'}\"\n",
    "}\n",
    "\n",
    "ex2_prompt = {\n",
    "    'role': 'assistant',\n",
    "    'name': 'example_user2',\n",
    "    'content': \"{'CHOICES': [सत्य, असत्य], 'TARGET': 'असत्य', 'CLEAN_CHOICES': [True, False], 'CLEAN_TARGET': 1}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbcbcc-e706-40ec-a552-d4584c59d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_data = []\n",
    "ip_tokens, op_tokens = 0, 0\n",
    "\n",
    "for i, elem in tqdm(enumerate(merged_ds.query('CLEANED_TYPE == \"true_false\"').itertuples()), total=merged_ds.query('CLEANED_TYPE == \"true_false\"').shape[0]):\n",
    "    try:\n",
    "        usr_prompt = {\n",
    "            'role': 'user',\n",
    "            'content': json.dumps({\n",
    "                'CHOICES': elem.CHOICES,\n",
    "                'TARGET': elem.TARGET\n",
    "            }, ensure_ascii=False)\n",
    "        }\n",
    "        op, tks = standardizer(\n",
    "            [sys_prompt, ex1_prompt, ex2_prompt, usr_prompt]\n",
    "        )\n",
    "        op.update({'QUESTION': elem.QUESTION})\n",
    "        standard_data.append(op)\n",
    "\n",
    "        ip_tokens += tks.prompt_tokens\n",
    "        op_tokens += tks.completion_tokens\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Input tokens: {ip_tokens}\\tOutput tokens: {op_tokens}')\n",
    "\n",
    "        # if i >= 5:\n",
    "        #     break\n",
    "    except Exception as err:\n",
    "        print(f'Error: {err} at {elem.Index}')\n",
    "\n",
    "print(f'Input tokens: {ip_tokens}\\tOutput tokens: {op_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f22a26-a4f6-482d-b608-a1ed8afb7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_ds = pd.DataFrame(standard_data)\n",
    "standard_ds = standard_ds.merge(merged_ds, on='QUESTION', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0db6a6-5c24-4b18-8b7d-b2b7c2891843",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_ds = standard_ds.query('CLEAN_TARGET.notna() and CLEAN_TARGET < 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d4844-a489-475a-bc78-6cb12ece6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually clean [27, 98]\n",
    "standard_ds.loc[98, 'CLEAN_TARGET'] = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b89a7c58-1dc0-49df-8b2c-8331c624db3a",
   "metadata": {},
   "source": [
    "### Verifying data\n",
    "- Send passage and question to GPT for QnA\n",
    "- Return one word answer\n",
    "- Verify with existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a942b-cfd8-47ef-be9f-3980e665b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ques_mapper = {\n",
    "    'fill_in_the_blanks': 'Answer this fill in the blanks question from the choices given only',\n",
    "    'true_false': 'Answer this True/False question in one word (True or False)',\n",
    "    'mcq': 'Answer this MCQ question by selecting the answer from the choices given only'\n",
    "    \n",
    "}\n",
    "\n",
    "sys_prompt = {\n",
    "    'role': 'system',\n",
    "    'content': dedent('''\n",
    "    You are a helpful assistant who answer questions based on the given passage.\n",
    "    The passage will be in Hindi/Hinglish. The answer needs to be in the same language of question. There can be multiple questions.\n",
    "    The format of the user query will be:\n",
    "\n",
    "    Passage\n",
    "    \"\"\n",
    "\n",
    "    Question 1\n",
    "    \"\"\n",
    "\n",
    "    Choices 1\n",
    "    \"\"\n",
    "\n",
    "    Task 1\n",
    "    \"\"\n",
    "\n",
    "    Always output in JSON {'1': <>, '2': <>}\n",
    "    Answer -1 if the question is nonsensical and choose from Choices if the choices are given.\n",
    "    ''').strip()\n",
    "}\n",
    "\n",
    "usr_content = dedent('''\n",
    "    Question {i}\n",
    "    {question}\n",
    "\n",
    "    Choices {i}\n",
    "    {choices}\n",
    "\n",
    "    Task {i}\n",
    "    {task}\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48821936-aae9-4a69-94e2-8b4e6647d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = merged_ds.query(\"CLEANED_TYPE=='fill_in_the_blanks'\").sample(n=1).iloc[0]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e043ed-231d-487c-b2a9-0f9db60a07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = GPTGenerator(model_id='gpt-3.5-turbo-1106')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19977f02-5bc0-4e28-98b6-738f69abff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_prompt = {\n",
    "    'role': 'user',\n",
    "    'content': usr_content.format(\n",
    "        passage=ex.content,\n",
    "        question=ex.QUESTION,\n",
    "        choices=ex.CHOICES,\n",
    "        task=prompt_ques_mapper[ex.CLEANED_TYPE]\n",
    "    )\n",
    "}\n",
    "\n",
    "op, tkns = engine([\n",
    "        sys_prompt,\n",
    "        usr_prompt\n",
    "    ], temperature=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff9ea7-3a98-49c8-9ffc-a490d8fcf35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validity = {\n",
    "    'output': [],\n",
    "    'link': [],\n",
    "    'question': []\n",
    "}\n",
    "\n",
    "ip_tokens, op_tokens = 0, 0\n",
    "i = 0\n",
    "\n",
    "for gp in tqdm(merged_ds.groupby(['link']), total=len(merged_ds.groupby(['link']))):\n",
    "    try:\n",
    "        all_quest = '''\n",
    "        Passage\n",
    "        {passage}\n",
    "        \n",
    "        '''.format(passage=gp[1]['content'].iloc[0])\n",
    "\n",
    "        links, ques = [], []\n",
    "        for idx, q in enumerate(gp[1].itertuples()):\n",
    "            all_quest += usr_content.format(\n",
    "                i=idx+1,\n",
    "                question=q.QUESTION,\n",
    "                choices=random.sample(q.CHOICES, len(q.CHOICES)) if q.CHOICES else q.CHOICES,\n",
    "                task=prompt_ques_mapper[q.CLEANED_TYPE]\n",
    "            )\n",
    "\n",
    "            links.append(gp[0][0])\n",
    "            ques.append(q.QUESTION)\n",
    "    \n",
    "    \n",
    "        usr_prompt = {\n",
    "            'role': 'user',\n",
    "            'content': dedent(all_quest.strip())\n",
    "        }\n",
    "    \n",
    "        messages = [sys_prompt, usr_prompt]\n",
    "        output, tks = engine(messages, temperature=1)\n",
    "    \n",
    "        validity['output'].extend(list(output.values()))\n",
    "        validity['link'].extend(links)\n",
    "        validity['question'].extend(ques)\n",
    "    \n",
    "        ip_tokens += tks.prompt_tokens\n",
    "        op_tokens += tks.completion_tokens\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Input tokens: {ip_tokens}\\tOutput tokens: {op_tokens}')\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f'Error: {err}')\n",
    "        continue\n",
    "\n",
    "    finally:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6018f9f0-978b-4f49-86ee-9f5e6e20790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validity = pd.DataFrame(validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c365e72-93aa-4a60-9132-2386ec0d7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with the existing dataset\n",
    "op = merged_ds.merge(validity, right_on=['link', 'question'], left_on=['link', 'QUESTION'], how='inner')\n",
    "op['CORRECT'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e739d26-fb8b-447c-89f4-af41ce284cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.query('CORRECT == True').shape, op.query('CORRECT == False').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3869f79-c2ba-4874-9879-043e289078c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_to_target_idx = [2, 37]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0bf94-46b6-4bf7-9b7b-1833db7968d4",
   "metadata": {},
   "source": [
    "### Cleaning and uploading\n",
    "- Remove incorrectly formatted QnA\n",
    "- Merge all datasets together\n",
    "- Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e323b93-e666-4604-ad7c-cd9b66ebf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "from copy import deepcopy\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a868c-b7e9-4d63-80a4-cb105e9f36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_url(url):\n",
    "    hash_object = hashlib.sha256()\n",
    "    hash_object.update(url.encode())\n",
    "    hex_digest = hash_object.hexdigest()\n",
    "\n",
    "    return hex_digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77f391-a322-497a-a43b-3d37f05bd219",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = deepcopy(merged_ds.query('CLEANED_TYPE != \"true_false\"'))\n",
    "part2 = deepcopy(standard_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6984776-a904-412e-a610-561e41bb7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.loc[:, 'PASSAGE_HASH'] = part1.PASSAGE_LINK.apply(lambda x: hash_url(x))\n",
    "part2.loc[:, 'PASSAGE_HASH'] = part2.PASSAGE_LINK.apply(lambda x: hash_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc1808-0813-4751-ae38-fcf77a8baeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = ['PASSAGE', 'QUESTION', 'TYPE', 'CHOICES', 'TARGET', 'PASSAGE_HASH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4918473-5407-48b1-a077-406934eda078",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = part1[['content', 'QUESTION', 'CLEANED_TYPE', 'CHOICES', 'TARGET', 'ENCODED_ID']]\n",
    "part1.columns = common_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecae29-f58d-47d5-892d-3e62c98dbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part2[['content', 'QUESTION', 'CLEANED_TYPE', 'CLEAN_CHOICES', 'CLEAN_TARGET', 'ENCODED_ID']]\n",
    "part2.columns = common_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdda7bc-00cb-4dbb-8c37-d69179f18c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([part1, part2], ignore_index=True)\n",
    "final_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb337ba-55c2-4268-8a64-9099ec8a2094",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hash = random.sample(list(final_df.PASSAGE_HASH.unique()), 10)\n",
    "train_hash = [x for x in list(final_df.PASSAGE_HASH.unique()) if x not in test_hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0c60d-21bb-4da3-bd61-2d40ab1c34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_hash), len(train_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3fecf-c65d-4daf-b1f0-615886d72df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = final_df.query('PASSAGE_HASH in @test_hash').reset_index(drop=True)\n",
    "train_df = final_df.query('PASSAGE_HASH in @train_hash').reset_index(drop=True)\n",
    "\n",
    "print(test_df.shape, train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180f837-19f6-4eff-8962-58c3cc37ea78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One time\n",
    "train_df.drop(50, inplace=True)\n",
    "train_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0264d-925a-445a-8517-313662ba80a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train_df.columns:\n",
    "    train_df[c] = train_df[c].astype(str)\n",
    "    test_df[c] = test_df[c].astype(str)\n",
    "\n",
    "train_df['TARGET'] = train_df['TARGET'].astype(int)\n",
    "test_df['TARGET'] = test_df['TARGET'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b160ec-edad-4954-8df4-3acb547be002",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a1f78-e715-474c-b834-b0b44e576191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.push_to_hub('cmeraki/hindi_eval_retrieval', token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb683c-99df-4737-ba6f-537b2dff4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.push_to_hub('cmeraki/hindi_eval_retrieval_private', token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aeb8ae-a6b9-4790-9919-091054aedb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
