{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rss_feed(url: str):\n",
    "    rss_xml = requests.get(url)\n",
    "\n",
    "    if rss_xml.status_code != 200:\n",
    "        print(f'Not able to query RSS feed page')\n",
    "        raise RuntimeError('Not able to query RSS feed page')\n",
    "\n",
    "    root = ET.fromstring(rss_xml.content)\n",
    "    items = root.findall('.//item')\n",
    "    titles = [i.find('./title').text.strip() for i in items]\n",
    "    links = [i.find('./link').text for i in items]\n",
    "\n",
    "    print(f'{len(links)} found')\n",
    "\n",
    "    return titles, links\n",
    "\n",
    "def get_individual_article(url: str, stop_phrases: List[str]):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f'Not able to query the article: {url}')\n",
    "        raise RuntimeError(f'Not able to query the article: {url}')\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    all_paras = [p.get_text() for p in soup.find_all('p')]\n",
    "\n",
    "    article_content = []\n",
    "    for para in all_paras:\n",
    "        for sp in stop_phrases:\n",
    "            if sp in para:\n",
    "                break\n",
    "        article_content.append(para)\n",
    "\n",
    "    # print(f'{len(all_paras)} paras found. {len(article_content)} paras parsed')\n",
    "\n",
    "    return '\\n\\n'.join(article_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_urls = [\n",
    "    'https://www.bhaskar.com/rss-v1--category-7140.xml',\n",
    "    'https://www.bhaskar.com/rss-v1--category-11215.xml',\n",
    "    'https://www.bhaskar.com/rss-v1--category-7911.xml',\n",
    "    'https://www.bhaskar.com/rss-v1--category-1051.xml',\n",
    "    'https://www.bhaskar.com/rss-v1--category-11616.xml'\n",
    "]\n",
    "phrases = ['पूरी खबर यहां पढ़ें...', 'ये खबर भी पढ़ें...', 'Copyright', 'पढ़ें पूरी खबर...', 'पूरी खबर पढ़ें...']\n",
    "sleep_time = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for rss_url in rss_urls:\n",
    "\n",
    "    print(f'Processing for {rss_url}')\n",
    "    rss_titles, rss_feed = get_rss_feed(url=rss_url)\n",
    "\n",
    "    for t, l in tqdm(zip(rss_titles, rss_feed), total=len(rss_feed)):\n",
    "        try:\n",
    "            article = get_individual_article(url=l, stop_phrases=phrases)\n",
    "            dataset.append({\n",
    "                'link': l,\n",
    "                'title': t,\n",
    "                'content': article\n",
    "            })\n",
    "\n",
    "        except Exception as err:\n",
    "            continue\n",
    "        time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in ds[4]['content'].split('\\n\\n'):\n",
    "    for p in phrases:\n",
    "        if p in elem:\n",
    "            print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in ds[4]['content'].split('\\n\\n'):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk('../data/retreival/20231228-1604/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mahout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
